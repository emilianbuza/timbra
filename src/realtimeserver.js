import WebSocket, { WebSocketServer } from "ws";
import dotenv from "dotenv";
import { createCalendarEvent } from "./calendar.js";
dotenv.config();

const OPENAI_MODEL =
  process.env.OPENAI_REALTIME_MODEL || "gpt-4o-realtime-preview-2024-10-01";
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

/**
 * Realtime-Server: verbindet Twilio Voice Streams mit OpenAI GPT-4 Realtime.
 * Pfad: /media-stream (muss mit TwiML <Stream> √ºbereinstimmen)
 */
export function initRealtimeServer(server) {
  const wss = new WebSocketServer({ server, path: "/media-stream" });
  console.log("üéß Realtime-Server wartet auf Twilio-Streams...");

  wss.on("connection", (ws) => {
    console.log("üìû Neuer Twilio-Stream verbunden");

    // streamSid ist KRITISCH f√ºr R√ºcksendung an Twilio!
    let streamSid = null;

    // === Verbindung zu OpenAI Realtime herstellen ===
    const openaiWs = new WebSocket(
      `wss://api.openai.com/v1/realtime?model=${OPENAI_MODEL}`,
      {
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          "OpenAI-Beta": "realtime=v1",
        },
      }
    );

    // === 1) Session konfigurieren (ZUERST!) ===
    openaiWs.on("open", () => {
      console.log("üß† Verbunden mit OpenAI Realtime API");

      // Komplette Session-Konfiguration
      const sessionConfig = {
        type: "session.update",
        session: {
          // Server VAD: automatische Erkennung wann User fertig spricht
          turn_detection: {
            type: "server_vad",
            threshold: 0.5,              // Empfindlichkeit (0-1)
            prefix_padding_ms: 300,      // Audio-Vorlauf
            silence_duration_ms: 500,    // Pause = Ende
          },
          // Audio-Format f√ºr Twilio (Œº-law, 8kHz)
          input_audio_format: "g711_ulaw",
          output_audio_format: "g711_ulaw",
          // Stimme (WICHTIG: nur alloy, echo, shimmer sind g√ºltig!)
          voice: "alloy",  
          // System-Instructions
          instructions: `Du bist die freundliche, empathische Praxisassistenz der Praxis Dr. Emilian Buza.

Verhalten:
- Sprich nat√ºrlich, ruhig und professionell auf Deutsch
- Begr√º√üe Anrufer herzlich: "Guten Tag, Praxis Dr. Emilian Buza, was kann ich f√ºr Sie tun?"
- Bei Terminwunsch: frage nach Datum und Uhrzeit
- Best√§tige am Ende: "Perfekt, ich trage das gleich f√ºr Sie ein."
- Halte Antworten kurz und pr√§zise (max. 2-3 S√§tze)`,
          // Audio + Text parallel
          modalities: ["text", "audio"],
          temperature: 0.8,
        },
      };

      console.log("üì§ Konfiguriere Session...");
      openaiWs.send(JSON.stringify(sessionConfig));

      // Nach Session-Update: Begr√º√üung triggern
      setTimeout(() => {
        console.log("üì§ Triggere initiale Begr√º√üung...");
        openaiWs.send(
          JSON.stringify({
            type: "response.create",
            response: {
              modalities: ["text", "audio"],
            },
          })
        );
      }, 250);
    });

    // === 2) Twilio -> OpenAI: Audio-Input weiterleiten ===
    ws.on("message", (raw) => {
      let data;
      try {
        data = JSON.parse(raw.toString());
      } catch {
        return; // Ung√ºltiges JSON ignorieren
      }

      // Stream-Start: streamSid extrahieren (KRITISCH!)
      if (data.event === "start") {
        streamSid = data.start?.streamSid || data.streamSid || null;
        console.log("ü™™ Twilio streamSid:", streamSid);
        return;
      }

      // Audio-Frames von Twilio ‚Üí OpenAI
      if (data.event === "media" && data.media?.payload) {
        if (openaiWs.readyState === WebSocket.OPEN) {
          openaiWs.send(
            JSON.stringify({
              type: "input_audio_buffer.append",
              audio: data.media.payload, // Base64 Œº-law
            })
          );
        }
        return;
      }

      // Stream-Ende signalisieren
      if (data.event === "stop") {
        console.log("üõë Twilio Stream-Stop");
        if (openaiWs.readyState === WebSocket.OPEN) {
          openaiWs.send(JSON.stringify({ type: "input_audio_buffer.commit" }));
        }
        return;
      }
    });

    // === 3) OpenAI -> Twilio: Audio-Output zur√ºcksenden ===
    let audioChunkCount = 0;

    openaiWs.on("message", async (raw) => {
      let msg;
      try {
        msg = JSON.parse(raw.toString());
      } catch {
        return;
      }

      // Debug: Session erfolgreich konfiguriert
      if (msg.type === "session.updated") {
        console.log("‚úÖ Session erfolgreich konfiguriert");
      }

      // Debug: Conversation started
      if (msg.type === "response.created") {
        console.log("üé¨ OpenAI generiert Antwort...");
        audioChunkCount = 0;
      }

      // Audio-Chunks zur√ºck an Twilio (MIT streamSid!)
      if (msg.type === "response.audio.delta" && msg.delta) {
        audioChunkCount++;
        if (audioChunkCount === 1) {
          console.log("üîä Audio-Streaming gestartet...");
        }

        if (streamSid && ws.readyState === WebSocket.OPEN) {
          ws.send(
            JSON.stringify({
              event: "media",
              streamSid: streamSid,  // OHNE das verwirft Twilio die Nachricht!
              media: {
                payload: msg.delta,  // Base64 Œº-law von OpenAI
              },
            })
          );
        }
      }

      // Audio fertig
      if (msg.type === "response.audio.done") {
        console.log(`‚úÖ Audio-Response komplett (${audioChunkCount} chunks)`);
      }

      // Transkrip: User-Input
      if (msg.type === "conversation.item.input_audio_transcription.completed") {
        console.log("üë§ User sagte:", msg.transcript);
      }

      // Transkrip: Assistant-Output
      if (msg.type === "response.output_item.done" && msg.item?.content) {
        const text = msg.item.content.find((c) => c.type === "text")?.text;
        if (text) {
          console.log("ü§ñ Assistant:", text);

          // Einfache Heuristik: Termin-Keywords erkennen
          const lower = text.toLowerCase();
          if (
            (lower.includes("termin") || lower.includes("trage")) &&
            (lower.includes("ein") || lower.includes("buchen"))
          ) {
            console.log("üìÖ Termin-Keyword erkannt ‚Üí Kalender-Event erstellen");
            try {
              await createCalendarEvent({
                summary: "Neuer Patiententermin (Sprachassistent)",
                description: `Automatisch erstellt\nText: ${text}`,
                startISO: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString(), // +1 Tag
              });
              console.log("‚úÖ Termin erfolgreich eingetragen");
            } catch (err) {
              console.error("‚ùå Kalender-Fehler:", err.message);
            }
          }
        }
      }

      // Fehler von OpenAI
      if (msg.type === "error") {
        console.error("‚ùå OpenAI Error:", msg.error);
      }
    });

    // === 4) Cleanup bei Disconnect ===
    ws.on("close", () => {
      console.log("‚ùå Twilio-Stream getrennt");
      if (openaiWs.readyState === WebSocket.OPEN) {
        openaiWs.close();
      }
    });

    openaiWs.on("close", () => {
      console.log("üîö OpenAI-Session beendet");
    });

    openaiWs.on("error", (err) => {
      console.error("‚ùå OpenAI WebSocket Error:", err.message);
    });
  });
}
